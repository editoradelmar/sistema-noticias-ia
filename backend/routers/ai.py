
"""
Router de IA - Solo acceso a modelos v√≠a llm_maestro. No se permite fallback ni texto suelto fuera de funciones.
"""
from fastapi import APIRouter, HTTPException, status, Depends
from sqlalchemy.orm import Session
from typing import Dict, List
import httpx
import uuid
from services.generador_ia import GeneradorIA
from core.database import get_db
from models import orm_models
from models.schemas import (
    ChatRequest,
    ChatResponse,
    AnalisisIARequest,
    AnalisisIAResponse,
    ResumenIAResponse,
    TipoAnalisisIA
)

router = APIRouter()

# Almacenamiento de conversaciones en memoria
conversaciones: Dict[str, List[dict]] = {}

# ==================== ENDPOINTS ====================

# Chat conversacional con IA usando modelo seleccionado
@router.post("/chat", response_model=ChatResponse)
async def chat_con_ia(request: ChatRequest, db: Session = Depends(get_db)):
    """
    Chat conversacional con IA (modelo configurable)
    - mensaje: Mensaje del usuario
    - conversacion_id: ID de conversaci√≥n (opcional)
    - contexto: Contexto adicional (opcional)
    - llm_id: ID del modelo LLM a usar
    """
    if not request.llm_id:
        raise HTTPException(status_code=400, detail="Debe especificar un llm_id v√°lido")
    llm = db.query(orm_models.LLMMaestro).filter(orm_models.LLMMaestro.id == request.llm_id, orm_models.LLMMaestro.activo == True).first()
    if not llm:
        raise HTTPException(status_code=404, detail=f"Modelo LLM con id {request.llm_id} no encontrado o inactivo")

    conv_id = request.conversacion_id or str(uuid.uuid4())
    if conv_id not in conversaciones:
        conversaciones[conv_id] = []
        
        # Agregar contexto de fecha autom√°ticamente al inicio de cada conversaci√≥n nueva
        from datetime import datetime
        import locale
        
        # Configurar locale para espa√±ol (fallback si no est√° disponible)
        try:
            locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')
        except:
            try:
                locale.setlocale(locale.LC_TIME, 'Spanish_Spain.1252')
            except:
                pass  # Usar locale por defecto
        
        ahora = datetime.now()
        fecha_sistema = ahora.strftime("%A, %d de %B de %Y a las %H:%M:%S")
        
        conversaciones[conv_id].append({
            "role": "system",
            "content": f"Fecha y hora actual del sistema: {fecha_sistema}. Usa esta informaci√≥n cuando sea relevante para c√°lculos temporales o referencias de fecha."
        })


    # Preparar historial de mensajes
    historial = conversaciones[conv_id].copy()
    mensaje_usuario = request.mensaje
    historial.append({"role": "user", "content": mensaje_usuario})

    # Limitar historial para evitar exceder l√≠mites de tokens del LLM
    # Mantener los √∫ltimos N mensajes para preservar contexto reciente
    MAX_MENSAJES_HISTORIAL = 20  # √öltimos 10 intercambios (20 mensajes)
    if len(historial) > MAX_MENSAJES_HISTORIAL:
        # Separar mensajes de sistema de los dem√°s
        mensajes_sistema = [msg for msg in historial if msg.get("role") == "system"]
        mensajes_conversacion = [msg for msg in historial if msg.get("role") != "system"]
        
        # Tomar los √∫ltimos mensajes de conversaci√≥n
        mensajes_recientes = mensajes_conversacion[-(MAX_MENSAJES_HISTORIAL - len(mensajes_sistema)):]
        
        # Combinar: sistema + conversaci√≥n reciente
        historial_truncado = mensajes_sistema + mensajes_recientes
    else:
        historial_truncado = historial

    # Generar respuesta usando el modelo seleccionado, enviando el historial truncado
    generador = GeneradorIA(db)
    try:
        respuesta_llm = generador.generar_contenido(
            llm=llm,
            prompt_contenido=historial_truncado,  # Enviar historial optimizado
            max_tokens=2000
        )
        respuesta_texto = respuesta_llm.get("contenido", "")
        tokens_usados = respuesta_llm.get("tokens_usados", 0)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error al generar respuesta con el modelo: {str(e)}")

    # Guardar en historial
    historial.append({"role": "assistant", "content": respuesta_texto})
    conversaciones[conv_id] = historial

    return ChatResponse(
        respuesta=respuesta_llm,  # dict completo
        conversacion_id=conv_id,
        tokens_usados=tokens_usados,
        metadata={
            "total_mensajes": len(conversaciones[conv_id]),
            "mensajes_enviados_llm": len(historial_truncado),
            "historial_truncado": len(historial) > MAX_MENSAJES_HISTORIAL
        }
    )

# ==================== HELPERS ====================

def obtener_noticia_por_id(noticia_id: int, db: Session) -> orm_models.Noticia:
    """Obtener noticia de PostgreSQL"""

    noticia = db.query(orm_models.Noticia).filter(orm_models.Noticia.id == noticia_id).first()
    if not noticia:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Noticia con ID {noticia_id} no encontrada"
        )
    return noticia

    # Guardar respuesta en historial
    conversaciones[conv_id].append({
        "role": "assistant",
        "content": respuesta_texto
    })

    return ChatResponse(
        respuesta=respuesta_texto,
        conversacion_id=conv_id,
        tokens_usados=tokens_usados
    )
    # Generar un resumen detallado de una noticia (solo modo simulado o v√≠a llm_maestro)
    # Obtener noticia de PostgreSQL
    noticia = obtener_noticia_por_id(noticia_id, db)
    noticia_dict = noticia.to_dict()
    
    # Solo modo simulado permitido aqu√≠
    print("‚ÑπÔ∏è Generando resumen simulado (solo permitido v√≠a llm_maestro)")
    contenido = noticia.contenido
    palabras = contenido.split()
    resumen = ' '.join(palabras[:30]) + "..."
    puntos_clave = [
        f"üìå Secci√≥n: {noticia.seccion.nombre if noticia.seccion else 'Sin secci√≥n'}",
        f"üìÖ Publicado el {noticia.fecha}",
        "‚ÑπÔ∏è Para res√∫menes m√°s inteligentes, use un modelo LLM v√°lido"
    ]
    
    # Actualizar noticia con el resumen en PostgreSQL
    noticia.resumen_ia = resumen
    db.commit()
    db.refresh(noticia)
    
    return ResumenIAResponse(
        noticia_id=noticia_id,
        resumen=resumen,
        puntos_clave=puntos_clave,
        longitud_original=len(noticia.contenido),
        longitud_resumen=len(resumen)
    )


@router.post("/analizar", response_model=AnalisisIAResponse)
async def analizar_noticia(
    request: AnalisisIARequest,
    db: Session = Depends(get_db)
):
    # Analizar una noticia con IA (solo modo simulado o v√≠a llm_maestro)
    noticia = obtener_noticia_por_id(request.noticia_id, db)
    
    # Preparar prompts
    prompts = {
        TipoAnalisisIA.RESUMEN: f"Resume en 3-4 oraciones:\n\nT√≠tulo: {noticia.titulo}\nContenido: {noticia.contenido}",
        TipoAnalisisIA.SENTIMENT: f"Analiza el sentimiento (positivo/neutral/negativo):\n\n{noticia.contenido}",
        TipoAnalisisIA.KEYWORDS: f"Extrae las 5 palabras clave:\n\n{noticia.contenido}",
        TipoAnalisisIA.TRADUCCION: f"Traduce al {request.idioma_destino or 'ingl√©s'}:\n\n{noticia.titulo}\n{noticia.contenido}"
    }
    
    prompt = prompts.get(request.tipo_analisis)
    
    # Solo modo simulado permitido aqu√≠
    resultado = f"[Modo Simulado] An√°lisis de '{noticia.titulo}': {noticia.seccion.nombre if noticia.seccion else 'Sin secci√≥n'}, {noticia.fecha}"
    
    return AnalisisIAResponse(
        noticia_id=request.noticia_id,
        tipo_analisis=request.tipo_analisis,
        resultado=resultado,
        metadata={
            "titulo_noticia": noticia.titulo,
            "timestamp": str(noticia.fecha)
        }
    )


@router.get("/conversaciones/{conversacion_id}")
async def obtener_conversacion(conversacion_id: str):
    # Obtener historial de conversaci√≥n
    if conversacion_id not in conversaciones:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Conversaci√≥n {conversacion_id} no encontrada"
        )
    
    return {
        "conversacion_id": conversacion_id,
        "mensajes": conversaciones[conversacion_id],
        "total_mensajes": len(conversaciones[conversacion_id])
    }


@router.delete("/conversaciones/{conversacion_id}")
async def eliminar_conversacion(conversacion_id: str):
    # Eliminar conversaci√≥n
    if conversacion_id in conversaciones:
        del conversaciones[conversacion_id]
        return {"success": True, "message": "Conversaci√≥n eliminada"}
    
    raise HTTPException(
        status_code=status.HTTP_404_NOT_FOUND,
        detail=f"Conversaci√≥n {conversacion_id} no encontrada"
    )
